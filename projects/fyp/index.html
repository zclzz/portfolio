<!DOCTYPE html>
<html>
<head>
  <!-- Google tag (gtag.js) -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=G-K1JBCZZQRE"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'G-K1JBCZZQRE');
  </script>
  <meta charset="utf-8">
  <meta name="description"
        content="Optimal Action Sequence Reordering: Advancing POMDP Solutions with Language Model Insights">
  <meta name="keywords" content="LLMs, Embodied, EIF">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <title>FYP Project</title>

  <link href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro"
        rel="stylesheet">

  <link rel="stylesheet" href="./static/css/bulma.min.css">
  <link rel="stylesheet" href="./static/css/bulma-carousel.min.css">
  <link rel="stylesheet" href="./static/css/bulma-slider.min.css">
  <link rel="stylesheet" href="./static/css/fontawesome.all.min.css">
  <link rel="stylesheet"
        href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
  <link rel="stylesheet" href="./static/css/index.css">
  <link rel="stylesheet" href="./static/css/header_sidebar.css">
  <link rel="icon" href="./static/images/favicon.svg">

  <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
  <script defer src="./static/js/fontawesome.all.min.js"></script>
  <script src="./static/js/bulma-carousel.min.js"></script>
  <script src="./static/js/bulma-slider.min.js"></script>
  <script src="./static/js/index.js"></script>

</head>
<body>
  <div class="header">
    <div class="header-inner"> <!-- Wrapper for better control -->
      <div class="header-name">
        <a href="/" style="text-decoration: none; color: inherit;">{ Chao Zhou; }</a>
      </div>
      <div class="header-content">
          <a href="https://chaozhoulim.com/#top">About me</a>
          <a href="https://chaozhoulim.com/#Experience">Experience</a>
          <a href="https://chaozhoulim.com/#Projects">Projects</a>
          <a href="https://chaozhoulim.com/#Awards">Awards</a>
      </div>
      <button class="hamburger">&#9776;</button>
    </div>
  </div>

  <div class="sidebar" id="mySidebar">
    <div class="sidebar-header">
        <span>Chao Zhou</span>
        <button class="closebtn" onclick="closeSidebar()">Ã—</button>
      </div>
    <p class="navigation-title">Navigation</p>
    <a href="https://chaozhoulim.com/#top">About me</a>
    <a href="https://chaozhoulim.com/#Experience">Experience</a>
    <a href="https://chaozhoulim.com/#Projects">Projects</a>
    <a href="https://chaozhoulim.com/#Awards">Awards</a>
  </div>
<section class="hero">
  <div class="hero-body">
    <div class="container is-max-desktop">
      <div class="columns is-centered">
        <div class="column has-text-centered">
          <h1 class="title is-1 publication-title" style="margin-top: 20px;">Strategic Task Execution: Integrating Large Language Models, POMDP, and Customized Reordering Policy for Sequence Selection</h1>
          <div class="is-size-5 publication-authors">
            <span class="author-block">Final Year Research Thesis,</span>
            <span class="author-block">National University of Singapore</span>
          </div>
          <div class="is-size-5 publication-authors">
            <span class="author-block">
              <a href="https://chaozhoulim.com/"><em>Chao Zhou Lim</em></a>, advised by Dr. Kim Jung-Jae and Dr. Goh Shen-Tat
            </span>
          </div>
          <div class="is-size-5 publication-authors">
            <span class="author-block">
              <em>May 2024</em>
            </span>
          </div>
        </div>
      </div>
      <div class="columns">
        <div class="column has-text-centered">
          <div class="publication-links">
            <!-- Code Link -->
            <span class="link-block">
              <a href="https://github.com/zclzz/ALFRED-challenge"
                 class="external-link button is-normal is-rounded is-dark">
                <span class="icon">
                  <i class="fab fa-github"></i>
                </span>
                <span>Code</span>
              </a>
            </span>
            <!-- Dataset Link -->
            <span class="link-block">
              <a href="https://github.com/askforalfred/alfred/tree/master/data"
                  class="external-link button is-normal is-rounded is-dark">
                <span class="icon">
                    <i class="far fa-images"></i>
                </span>
                <span>Dataset</span>
              </a>
            </span>
          </div>
        </div>
      </div>

      <div class="is-size-5 publication-authors" style="text-align: center; margin-bottom: 30px;">
        <span class="author-block" style="display: inline-block; width: 70%;">
          Skills: Natural Language Processing &bull; Large Language Models &bull; AI Planning and Decision Making &bull; Reinforcement Learning
        </span>
      </div>

      <!-- New row with two columns -->
      <div class="columns is-mobile" style="border-bottom: 1px solid #ccc; margin-bottom: 0px;">
        <div class="column has-text-left">
          <!-- Left-aligned text -->
          Project Portfolio
        </div>
        <div class="column has-text-right">
          <!-- Right-aligned text -->
          7 min read
        </div>
      </div>
    </div>
  </div>
</section>

<section class="hero teaser">
  <div class="container is-max-desktop">
    <div class="hero-body" style="text-align: center;"> <!-- Ensures all content in hero-body is centered -->
      <h2 class="subtitle has-text-centered">
        Goal: Place a clean filled mug at the coffee maker
      </h2>
      <!-- centre the video -->
      <video id="teaser" autoplay muted loop playsinline height="100%" style="display: block; margin: auto; margin-bottom: 10px;">
        <source src="./static/videos/alfred.mp4"
                type="video/mp4">
      </video>
      <p style="margin-bottom: 30px;">
        High-level task instructions are inputted into the LLM, which then decomposes them into a sequence of actionable steps executed by the agent in the <a href="https://ai2thor.allenai.org/demo/">THOR</a> virtual environment.
      </p>
      <h2 class="subtitle has-text-centered">
        <p>
          Plan: Pick up the mug -> go to the sink basin -> place the mug in the sink -> turn the faucet on -> turn the faucet off -> walk to the coffee maker -> place the mug
        </p>
      </h2>
    </div>
  </div>
</section>

<section class="section">
  <div class="container is-max-desktop">
    <!-- Abstract. -->
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">Abstract</h2>
        <div class="content has-text-justified">
          <p>
            My final-year research investigates the future of Embodied Instruction Following (EIF), 
            which involves the use of mobile manipulator robots that perform household tasks based on 
            natural language instructions. EIF aims to bridge the gap between simulated environments 
            and real-world applications, allowing robots to operate effectively in human spaces. 
          </p>
          <p>
            My research extends the capabilities of two state-of-the-art embodied agents, 
            <a href="https://arxiv.org/abs/2110.07342">FILM</a> and <a href="https://arxiv.org/abs/2211.03267">Prompter</a>, 
            addressing their limitations in handling high-level task instructions. I propose two novel methods 
            that employ large language models (LLMs) to predict top promising action sequences and a reordering policy 
            to optimize the selection from these sequences for partially observed environmental states.
          </p>
          <p>
            Agents are evaluated against <a href="https://askforalfred.com/">ALFRED</a> dataset, a benchmark for learning
            a mapping from natural language instructions and egocentric vision to sequences of
            actions for household tasks. My proposed strategy is successful in surpassing both
            my baseline systems, <strong>significantly outperforming</strong> my baselines' state-of-the-art model,
            reaching a 48.59% success rate and claiming <strong>13th place</strong> on a globally competitive
            <a href="https://leaderboard.allenai.org/alfred/submissions/public">leaderboard</a> that features contributions from researchers around the world.
          </p>
        </div>
      </div>
    </div>
    <!--/ Abstract. -->

  </div>
</section>

<section class="section">
  <div class="container is-max-desktop">
    <div class="columns is-centered">
      <div class="column is-full-width">
        <h2 class="title is-3" style="text-align: left;">The Problem</h2>
        <div class="content has-text-justified">
          <!-- Center only the image, header is already centered -->
          <img src="./static/images/comm_error.png" style="width: 100%; display: block; margin-left: auto; margin-right: auto; margin-bottom: 20px;">
          <p style="text-align: center; font-size: 14px;">
            Figure 1: (a) Failure analysis of baseline model, (b) miscommunication errors in high-level task instructions.
          </p>
          <p>
            Miscommunication between humans and agents continues to be a significant challenge in task-oriented interactions, as highlighted by failure analysis 
            across dataset. These miscommunication errors often arise from ambiguously worded or contradictory high-level task instructions provided by humans. 
            Objects that humans may view as similar or identical, are different to agents, especially in environments like THOR, as they are recognized as distinct objects. This discrepancy 
            can lead to errors in task execution, where agents either interact with incorrect targets or fail to identify the correct ones, resulting in high rates of goal 
            undetected errors. Although such scenarios mirror real-life communication challenges, expecting humans to overly simplify or alter their natural language use is impractical. 
            Instead, there is a pressing need for agents to be developed with robust capabilities to interpret and navigate through these miscommunication errors effectively, 
            ensuring more reliable and successful task completion.
          </p>

          <p style="text-align: center; font-size: 14px;">
            Table 1: Example of miscommunication errors in high-level task instructions in the ALFRED dataset.
          </p>
          <table border="1" style="width:100%; border-collapse:collapse;">
            <tr style="text-align: center; background-color: #f2f2f2;">
                <th>Error Type</th>
                <th>High Level Task</th>
                <th>Ground Truths</th>
            </tr>
            <tr style="text-align: left;">
                <td>(Ambiguous) Example A</td>
                <td>"Turn on the living room lamp"</td>
                <td>Task type: look at obj in light, <span style="color:red;">object target: Vase</span>, moveable receptacle target: None, parent target: None, sliced: 0</td>
            </tr>
            <tr style="text-align: left;">
                <td>(Ambiguous) Example B</td>
                <td>"Put cup in the sink"</td>
                <td>Task type: pick and place with movable recep, <span style="color:red;">object target: Fork</span>, moveable receptacle target: Cup, parent target: Sink Basin, sliced: 0</td>
            </tr>
            <tr style="text-align: left;">
                <td>(Contradicting) Example C</td>
                <td>"Place a cold lettuce on the <span style="color:red;">table</span>"</td>
                <td>Task type: cool and place, object target: Lettuce, moveable receptacle target: None, <strong>parent target: Counter Top</strong>, sliced: 0</td>
            </tr>
            <tr style="text-align: left;">
                <td>(Contradicting) Example D</td>
                <td>"Put a <span style="color:red;">cup</span> with spoon on the counter to the left of the stove"</td>
                <td>Task type: pick and place with movable recep, object target: Spoon, <strong>moveable receptacle target: Mug</strong>, parent target: Counter Top, sliced: 0</td>
            </tr>
          </table>
          <p>
            Ambiguity refers to tasks that are too vague or provide little to
            no helpful information while contradiction errors refer to instructions that contain
            information that deviates from the ground truth. Table 1 shows two examples each of
            both vague and contradicting instructions and their corresponding ground truths.

            Task type is one of the seven task types in the ALFRED dataset. Object targets refer to moveable objects that the agent should interact
            with. Moveable receptacles are items that the agent can use to put small items in
            to fulfill task type of stack and place. The parent target is a receptacle for the
            agent to place the object target on (the object targetâ€™s final destination). Lastly,
            the "sliced" argument represents if the task involves cutting/slicing objects with a
            knife. In Table 1 the high-level instruction of ambiguous example A tasks the
            agent to "turn on the living room lamp" but does not specify the need for the object
            target which in this case is a "Vase", as required by the ground truth for the task to
            succeed if executed correctly. The LLM used to predict the instruction arguments
            will not know that a "Vase" is required for this task and will ultimately result in a
            wrong or â€™Noneâ€™ type prediction (no target objects required which is impossible as
            every task in ALFRED requires interacting with a target object).
          </p>
          <p>
            On the other hand, the table also demonstrates contradictions in the task
            dataset where different objects and moveable receptacles or parent targets were
            specified in the high-level instructions, which differ from the ground truths. In
            contradicting example C, the given human instruction tasks the agent to "place a
            cold lettuce on the table", which takes place in the scene of kitchen. This is vague
            and wrong according to the ground truth, and a clearer, correct task instruction
            aligning with its ground truth would be "place a cold lettuce on the countertop".
          </p>
          <p>
            The failure analysis sets a basis of the goal of my FYP, which is to develop a methodolgy to handle these natural language miscommunication errors effectively
            and improve the success rate of the agent in executing high-level task instructions, ultimately surpassing my state-of-the-art baseline systems.
          </p>

        </div>
      </div>
    </div>
  </div>
</section>


<section class="section">
  <div class="container is-max-desktop">
    <!-- Reordering Policy. -->
    <div class="columns is-centered has-text-centered">
      <div class="column is-full-width">
        <h2 class="title is-3" style="text-align: left;">Methodolgy</h2>
        <div class="content has-text-justified">
          <p>
            My proposed strategy enhances two key aspects of Prompter: language understanding
            and interaction planning. The language understanding component leverages
            the LLM to parse complex task instructions into multiple, task-specific arguments.
            These distilled instruction arguments are then relayed to the planner, which devises a
            tailored action plan for each set of instruction arguments to generate multiple action
            sequences. Following a partially observable Markov decision strategy, I utilized the
            agentâ€™s egocentric vision and object recognition to formulate an optimal reordering
            policy. The policy captures the top action sequences from the language model
            and reorders them according to a sophisticated reordering policy, finally taking the
            best action sequence that suits the task according to the agentâ€™s environment.
          </p>
          <h2 class="title is-small" style="text-align: left; font-size: 20px;">1. Improved Language Understanding</h2>
          <img src="./static/images/predictions.png" style="width: 100%; display: block; margin-left: auto; margin-right: auto; margin-bottom: 20px;">
          <p style="margin-bottom: 30px; text-align: center; font-size: 14px;">
            Figure 2: Considering top k candidates from the LLM rather than using greedy decoding to select the best action sequence.
          </p>

          <p>
            I evaluate the performance of various language models I have trained to determine
            the most effective one. Through this comparison, I found the Text-to-text Transfer Tansformer (T5) model to be the
            most suitable for my strategy in addressing the ALFRED challenge. Subsequently,
            I further enhance the T5 modelâ€™s accuracy by applying a hyperparameter tuning,
            and beam search algorithm to refine its prediction capabilities. The beam search
            algorithm, by considering multiple hypotheses at once, allows for a more nuanced and
            comprehensive analysis of potential outcomes, significantly increasing the likelihood
            of selecting the most accurate instruction arguments. This enhanced approach not
            only streamlines the process by consolidating the need for multiple models into a
            singular, more capable model but also improves the overall efficiency and accuracy of
            the system. By integrating the T5 model with a beam search refinement, the strategy
            demonstrates a marked improvement in handling complex and vague instruction sets,
            thus providing a robust solution for the intricacies involved in solving the ALFRED
            challenge.
          </p>
          <img src="./static/images/beam_search.png" style="width: 100%; display: block; margin-left: auto; margin-right: auto; margin-bottom: 20px;">
          <p style="margin-bottom: 30px; text-align: center; font-size: 14px;">
            Figure 3: Beam search algorithm considers multiple hypotheses at once to refine the prediction of instruction arguments.
          </p>
          <p>
            Unlike greedy algorithms which only keep the single best state, or breadth-first search, which expands all
            nodes, Beam Search balances between these approaches by maintaining a predefined
            width of the beam, denoted as B. This width controls the number of nodes expanded
            at each level of the search, allowing Beam Search to efficiently navigate through
            the vast search space of possible text sequences while mitigating the computational
            expense associated with breadth-first search. In the context of ALFRED, the Beam
            Search algorithm is utilized during the decoding phase, where the T5 model aims to
            generate a sequence of tokens (words) that form the instructional arguments.
          </p>
          <p>
            At each time step, the model computes the probability of the next word from its
            vocabulary, given the previous words, and retains the top 5 words with the highest
            computed probability. For the sake of brevity and illustration, I have omitted other
            branches of the search space, and arbitrary probability values (shown in brackets)
            were used. For each of the top 5 words, another set of probabilities for the top 5 words
            are computed as well and the process repeats until the generated sentence encounters
            an end-of-sentence (EOS) token. The overall probabilities of the generated sentences
            are computed, forming subsequent beam predictions. From Figure 5.3, it can be
            observed that the top predictions generated from the task instruction are not always
            correct, and more exploration of the possible combinations in the search space is
            required, especially since the task instruction contradicts the ground truth.
          </p>


          <h2 class="title is-small" style="text-align: left; font-size: 20px;">2. Action Sequence Reordering Policy</h2>
          <img src="./static/images/reordering_policy.png" style="width: 100%; display: block; margin-left: auto; margin-right: auto; margin-bottom: 20px;">
          <p style="margin-bottom: 30px; text-align: center; font-size: 14px;">
            Figure 4: The agent updates an object count vector during exploration to assess the likelihood of task completion for each action sequence
          </p>
          <p>
            After obtaining a top k action sequences from the large language model, the reordering policy aims to select the optimal sequence that maximizes the likelihood of task completion.
            I introduce an initial exploration phase of 100 steps for the agent. During
            this phase, the agent does a random search of the environment to observe and
            compile a count of all visible objects, which is then used to initialize the
            object count vector. This vector is updated at each time step to reflect the current state of the environment.
          </p> 
          <video id="example" autoplay muted loop playsinline height="100%" style="display: block; margin: auto; margin-bottom: 10px; margin-top: 10px;">
            <source src="./static/videos/example.mp4"
                    type="video/mp4">
          </video>
          <p style="text-align: center; font-size: 14px;">
            Figure 5: At T = 100, the agent applies the reordering policy to select the best action sequence to execute the task: place lettuce on CounterTop.
          </p>
          <p>
            Each action sequence is evaluated by calculating the likelihood of task completion based on the object count vector and the action sequence. It does so by assigning
            higher utility score to sequences whose objects were observed more frequently during the exploration phase, while penalizing sequences that require objects that were not observed. 
            Unseen receptacles are penalized more heavily than unseen objects, due the the higher likelihood of unseen receptacles leading to task failure. The agent then selects the sequence with the highest utility score to execute.
          </p>
          <p>
            By exploring the environment initially before deciding its best course of action,
            the agent gains critical insights into the current state, allowing it to strategically
            prioritize and select the most viable action sequence. This preliminary exploration
            is instrumental in navigating the complexities and uncertainties inherent in dynamic
            settings, ultimately leading to more informed and effective decision-making under
            uncertainty.
          </p>

        </div>
      </div>
    </div>
    <!--/ Reordering Policy. -->
  </div>
</section>


<section class="hero is-light is-small">
  <div class="container is-max-desktop">
    <div class="columns is-centered has-text-centered">
      <div class="column is-full-width">
        <h2 class="title is-3" style="text-align: left;">Results</h2>
        <div class="content has-text-justified">
          <p>
            I employed <span class="text-color" style="color: blue;"><a href="https://askforalfred.com/">ALFRED</a></span> to evaluate my method. In ALFRED, environments are categorized into three splits: 'train,' 'validation,' and 'test.' 
            Both the validation and test environments are split further into 'seen' and 'unseen' categories to evaluate how well the system generalizes. The main metric used is the success rate, 
            referred to as 'SR,' which calculates the proportion of successfully completed tasks. Another important metric is the goal-condition success rate, abbreviated as 'GC,' which quantifies 
            the proportion of goal conditions that have been met. Additionally, path-length-weighted (PLW) scores are used to adjust the SR and GC metrics based on the length of the actions performed by the agent.
          </p> 
          <p>
            My proposed method achieved a 48.59% success rate on the unseen test split, surpassing both my state-of-the-art baseline systems, in both components of language understanding and 
            navigation. My agent also attained a ranking of 12th place on the ALFRED Challenge <span class="text-color" style="color: blue;"><a href="https://leaderboard.allenai.org/alfred/submissions/public">leaderboard</a></span>,
            as of the time of this writing. 
            The results demonstrate the effectiveness of my proposed methods in handling high-level task instructions
            and optimizing action sequences for partially observed environmental states.
          </p>
          <p style="text-align: center; font-size: 14px;">
            Table 2: Comparative analysis of my model against my state-of-the-art baseline systems with underlined values indicating the best performance in each comparison.
          </p>
          <table style="width:100%; border-collapse: collapse; margin: 20px 0; border: 1px solid black;">
            <tr>
                <th style="background-color: #f2f2f2; padding: 8px; border: 1px solid black;">Metrics</th>
                <th style="background-color: #f2f2f2; padding: 8px; border: 1px solid black;">My Agent</th>
                <th style="background-color: #f2f2f2; padding: 8px; border: 1px solid black;">Prompter</th>
                <th style="background-color: #f2f2f2; padding: 8px; border: 1px solid black;">FILM</th>
            </tr>
            <tr>
                <td style="padding: 8px; border: 1px solid black;" colspan="4"><strong>Validation Unseen Set:</strong></td>
            </tr>
            <tr>
                <td style="padding: 8px; border: 1px solid black;">Total Episodes: 821</td>
                <td style="padding: 8px; border: 1px solid black;" colspan="3"></td>
            </tr>
            <tr>
                <td style="padding: 8px; border: 1px solid black;">Success Rate (SR)</td>
                <td style="padding: 8px; border: 1px solid black;"><u>0.555</u></td>
                <td style="padding: 8px; border: 1px solid black;">0.533</td>
                <td style="padding: 8px; border: 1px solid black;">0.201</td>
            </tr>
            <tr>
                <td style="padding: 8px; border: 1px solid black;">Goal Condition (GC) Success</td>
                <td style="padding: 8px; border: 1px solid black;"><u>0.654</u></td>
                <td style="padding: 8px; border: 1px solid black;">0.630</td>
                <td style="padding: 8px; border: 1px solid black;">0.325</td>
            </tr>
            <tr>
                <td style="padding: 8px; border: 1px solid black;">PLWSR</td>
                <td style="padding: 8px; border: 1px solid black;">0.137</td>
                <td style="padding: 8px; border: 1px solid black;"><u>0.196</u></td>
                <td style="padding: 8px; border: 1px solid black;">NA</td>
            </tr>
            <tr>
                <td style="padding: 8px; border: 1px solid black;">PLWGC</td>
                <td style="padding: 8px; border: 1px solid black;">0.158</td>
                <td style="padding: 8px; border: 1px solid black;"><u>0.217</u></td>
                <td style="padding: 8px; border: 1px solid black;">NA</td>
            </tr>
            <tr>
                <td style="padding: 8px; border: 1px solid black;" colspan="4"><strong>Test Unseen Set:</strong></td>
            </tr>
            <tr>
                <td style="padding: 8px; border: 1px solid black;">Total Episodes: 1529</td>
                <td style="padding: 8px; border: 1px solid black;" colspan="3"></td>
            </tr>
            <tr>
                <td style="padding: 8px; border: 1px solid black;">Leaderboard Ranking</td>
                <td style="padding: 8px; border: 1px solid black;"><u>13</u></td>
                <td style="padding: 8px; border: 1px solid black;">19</td>
                <td style="padding: 8px; border: 1px solid black;">27</td>
            </tr>
            <tr>
                <td style="padding: 8px; border: 1px solid black;">Success Rate (SR)</td>
                <td style="padding: 8px; border: 1px solid black;"><u>0.486</u></td>
                <td style="padding: 8px; border: 1px solid black;">0.426</td>
                <td style="padding: 8px; border: 1px solid black;">0.265</td>
            </tr>
            <tr>
                <td style="padding: 8px; border: 1px solid black;">Goal Condition (GC) Success</td>
                <td style="padding: 8px; border: 1px solid black;"><u>0.598</u></td>
                <td style="padding: 8px; border: 1px solid black;">0.588</td>
                <td style="padding: 8px; border: 1px solid black;">0.364</td>
            </tr>
            <tr>
                <td style="padding: 8px; border: 1px solid black;">Path Length Weighted SR (PLWSR)</td>
                <td style="padding: 8px; border: 1px solid black;">0.155</td>
                <td style="padding: 8px; border: 1px solid black;"><u>0.208</u></td>
                <td style="padding: 8px; border: 1px solid black;">0.106</td>
            </tr>
            <tr>
                <td style="padding: 8px; border: 1px solid black;">Path Length Weighted GC (PLWGC)</td>
                <td style="padding: 8px; border: 1px solid black;">0.190</td>
                <td style="padding: 8px; border: 1px solid black;"><u>0.262</u></td>
                <td style="padding: 8px; border: 1px solid black;">0.143</td>
            </tr>
          </table>
        
        </div>
      </div>
    </div>
  </div>
</section>


<footer class="footer">
  <div class="container">
    <div class="content has-text-centered">
      <a class="icon-link" href="https://github.com/zclzz/ALFRED-challenge" class="external-link" disabled>
        <i class="fab fa-github"></i>
      </a>
    </div>
    <div class="columns is-mobile" style="border-top: 1px solid #ccc; margin-bottom: 0px;">
      <div class="column has-text-left">
        <!-- Left-aligned text -->
        Last updated May 2024
      </div>
      <div class="column has-text-right">
        <!-- Right-aligned text -->
        Website design inspired by Park Keunhong
      </div>
    </div>
</div>
</footer>
<script>
  document.addEventListener('DOMContentLoaded', function() {
      const hamburger = document.querySelector('.hamburger');
      const sidebar = document.getElementById('mySidebar');
  
      // Function to toggle the sidebar
      function toggleSidebar() {
          if (sidebar.style.width === '300px') {
              sidebar.style.width = '0'; // Close the sidebar
          } else {
              sidebar.style.width = '300px'; // Open the sidebar
          }
      }
  
      // Function to close the sidebar
      window.closeSidebar = function() {
          sidebar.style.width = '0';
      }
  
      // Event listener for hamburger icon
      hamburger.addEventListener('click', function() {
          toggleSidebar();
      });
  
      // Optional: Close sidebar when a link inside is clicked
      document.querySelectorAll('.sidebar a').forEach(link => {
          link.addEventListener('click', closeSidebar);
      });
  
      // Listen for window resize to automatically close the sidebar on larger screens
      window.addEventListener('resize', function() {
          if (window.innerWidth > 768) {
              closeSidebar(); // Close the sidebar when the screen is larger than 768px
          }
      });
  });

  </script>


</body>
</html>
